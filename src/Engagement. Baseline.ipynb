{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engagement\n",
    "\n",
    "### Analyzing data from 2015/2016\n",
    "\n",
    "* This will be our baseline\n",
    "* This dataset was only used to train our models\n",
    "* No notifications were sent to students that year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = { 'family': 'DejaVu Sans', 'weight': 'bold', 'size': 22 }\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grades = pd.read_json(os.path.join(data_path, 'grades.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3,137'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:,}'.format(len(df_grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gain Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_index(e1, e2):\n",
    "    return float(e2 - e1) / e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_gain_index(e1, e2):\n",
    "    if e1 == 0 and e2 == 0:\n",
    "        return 0\n",
    "    elif e1 == 0:\n",
    "        return 1\n",
    "    gi = gain_index(e1, e2)\n",
    "    if gi > 1:\n",
    "        return 1\n",
    "    return gi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course: CA117, Academic year: 2015/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_course = 'ca117'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_academic_year = (2015, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grades(course, academic_year):\n",
    "    return df_grades[(df_grades['module'] == course) & \n",
    "                     (df_grades['academic_year_0'] == academic_year[0]) &\n",
    "                     (df_grades['academic_year_1'] == academic_year[1])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_ca117 = df_grades.iloc[get_grades(_course, _academic_year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grades_ca117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_names_ca117 = grades_ca117.user.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(student_names_ca117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_weeks_ca117 = sorted(grades_ca117.exam_week.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 12]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_weeks_ca117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_improvement(student_names, exam_weeks, grades, debug=False):\n",
    "    \n",
    "    marks = {}\n",
    "    normgi = {}\n",
    "    diff = {}\n",
    "    \n",
    "    for student_name in student_names:\n",
    "        \n",
    "        prev = None\n",
    "        improvement = None\n",
    "        \n",
    "        for exam_week in exam_weeks:\n",
    "            \n",
    "            grade = 0\n",
    "            grade_index = grades[(grades['user'] == student_name) &\n",
    "                                 (grades['exam_week'] == exam_week)].index\n",
    "            if len(grade_index) > 0:\n",
    "                grade = df_grades.iloc[grade_index[0]]['grade']\n",
    "                \n",
    "            marks.setdefault(exam_week, {})\n",
    "            marks[exam_week][student_name] = grade\n",
    "            \n",
    "            if debug: print('Student: {}, Exam week: {}, Grade: {}'.format(student_name, exam_week, grade))\n",
    "            \n",
    "            if prev is not None:\n",
    "                improvement = normalized_gain_index(prev, grade)\n",
    "                if debug: print('Student: {}, Improvement: {:.2f}'.format(student_name, improvement))\n",
    "                normgi[student_name] = improvement\n",
    "                diff[student_name] = grade - prev\n",
    "                \n",
    "            prev = grade\n",
    "            \n",
    "    return normgi, diff, marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normgi_ca117, diff_ca117, marks_ca117  = get_improvement(student_names_ca117, exam_weeks_ca117, grades_ca117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 40\n",
    "\n",
    "def get_pass_fail_cohorts(student_names, exam_weeks, grades):\n",
    "\n",
    "    passing, failing = [], []\n",
    "    \n",
    "    first_exam = exam_weeks[0]\n",
    "\n",
    "    for student_name in student_names:\n",
    "\n",
    "        grade = 0\n",
    "        grade_index = grades[(grades['user'] == student_name) &\n",
    "                             (grades['exam_week'] == first_exam)].index\n",
    "        if len(grade_index) > 0:\n",
    "            grade = df_grades.iloc[grade_index[0]]['grade']\n",
    "\n",
    "        if grade >= THRESHOLD:\n",
    "            passing.append(student_name)\n",
    "        else:\n",
    "            failing.append(student_name)\n",
    "\n",
    "    return passing, failing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_ca117, failing_ca117 = get_pass_fail_cohorts(student_names_ca117, exam_weeks_ca117, grades_ca117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_fail_dict_ca117 = {\n",
    "    'Pass': passing_ca117,\n",
    "    'Fail': failing_ca117,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(student_dict, normgi, diff, marks, exam_weeks):\n",
    "    \n",
    "    # Store improvements\n",
    "    d = {}\n",
    "    \n",
    "    for name, students in student_dict.items():\n",
    "        \n",
    "        num_students = len(students)\n",
    "        \n",
    "        print('Group: {} (# {})'.format(name, num_students))\n",
    "        \n",
    "        for exam_week in exam_weeks:\n",
    "            # Marks\n",
    "            mrks = [ value for student_name, value in marks[exam_week].items() if student_name in students ]    \n",
    "            # Avg\n",
    "            mrks_avg = np.mean(mrks)\n",
    "            # Std. deviation\n",
    "            mrks_std = np.std(mrks)\n",
    "            print('Marks Exam Week {}, Avg: {:.2f} ({:.2f})'.format(exam_week, mrks_avg, mrks_std))\n",
    "        \n",
    "        # Array of improvements\n",
    "        improvements = [ value for student_name, value in normgi.items() if student_name in students ]\n",
    "        d[name] = improvements\n",
    "        \n",
    "        # Avg\n",
    "        improv_avg = np.mean(improvements)\n",
    "        # Std. deviation\n",
    "        improv_std = np.std(improvements)\n",
    "        \n",
    "        # Differences\n",
    "        differences = [ value for student_name, value in diff.items() if student_name in students ]\n",
    "        \n",
    "        # Avg\n",
    "        diff_avg = np.mean(differences)\n",
    "        # Std. deviation\n",
    "        diff_std = np.std(differences)\n",
    "              \n",
    "        print('* Improvement Avg: {:.2f} ({:.2f}), Diff Avg: {:.2f} ({:.2f})'.format(\n",
    "            mrks_avg, mrks_std, improv_avg, improv_std, diff_avg, diff_std))\n",
    "        \n",
    "    # T-test\n",
    "    keys = list(student_dict.keys())\n",
    "    group_one = d[keys[0]]\n",
    "    group_two = d[keys[1]]\n",
    "    ttest = ttest_ind(group_one, group_two)\n",
    "    print(ttest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Pass (# 66)\n",
      "Marks Exam Week 6, Avg: 75.23 (20.08)\n",
      "Marks Exam Week 12, Avg: 55.06 (29.94)\n",
      "* Improvement Avg: 55.06 (29.94), Diff Avg: -0.28 (0.36)\n",
      "Group: Fail (# 83)\n",
      "Marks Exam Week 6, Avg: 14.70 (13.65)\n",
      "Marks Exam Week 12, Avg: 24.40 (24.74)\n",
      "* Improvement Avg: 24.40 (24.74), Diff Avg: 0.26 (0.71)\n",
      "Ttest_indResult(statistic=-5.6492908116991485, pvalue=8.085760644466663e-08)\n"
     ]
    }
   ],
   "source": [
    "evaluate(pass_fail_dict_ca117, normgi_ca117, diff_ca117, marks_ca117, exam_weeks_ca117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students_ca117 = pd.read_csv('../data/students-ca117-2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_characteristics(dic, df_students):\n",
    "\n",
    "    for option in dic:\n",
    "        \n",
    "        # Students\n",
    "        student_names = dic[option]\n",
    "        \n",
    "        # Group\n",
    "        df_group = df_students[df_students['Username'].isin(student_names)]\n",
    "\n",
    "        # Age\n",
    "        age_mean = np.mean(df_group['Age'])\n",
    "        \n",
    "        # CAO Points\n",
    "        points = df_group[df_group['Route'] == 'Leaving Cert.']['CAO Points']\n",
    "        cao_mean = np.mean(points)\n",
    "        \n",
    "        print('{} - # students: {}, Age: {:.2f}, CAO ({}): {:.2f}'.format(\n",
    "            option, len(df_group), age_mean, len(points), cao_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass - # students: 66, Age: 18.77, CAO (49): 445.31\n",
      "Fail - # students: 83, Age: 19.07, CAO (61): 430.08\n"
     ]
    }
   ],
   "source": [
    "compare_characteristics(pass_fail_dict_ca117, df_students_ca117)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course: CA114, Academic year: 2015/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_course = 'ca114'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_academic_year = (2015, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_ca114 = df_grades.iloc[get_grades(_course, _academic_year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grades_ca114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_names_ca114 = grades_ca114.user.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(student_names_ca114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_weeks_ca114 = sorted(grades_ca114.exam_week.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 12]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_weeks_ca114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "normgi_ca114, diff_ca114, marks_ca114 = get_improvement(student_names_ca114, exam_weeks_ca114, grades_ca114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_ca114, failing_ca114 = get_pass_fail_cohorts(student_names_ca114, exam_weeks_ca114, grades_ca114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_fail_dict_ca114 = {\n",
    "    'Pass': passing_ca114,\n",
    "    'Fail': failing_ca114,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Pass (# 24)\n",
      "Marks Exam Week 6, Avg: 64.17 (22.35)\n",
      "Marks Exam Week 12, Avg: 64.17 (34.15)\n",
      "* Improvement Avg: 64.17 (34.15), Diff Avg: 0.05 (0.59)\n",
      "Group: Fail (# 51)\n",
      "Marks Exam Week 6, Avg: 5.88 (9.11)\n",
      "Marks Exam Week 12, Avg: 41.96 (31.75)\n",
      "* Improvement Avg: 41.96 (31.75), Diff Avg: 0.65 (0.65)\n",
      "Ttest_indResult(statistic=-3.744705693615501, pvalue=0.00035779664895052414)\n"
     ]
    }
   ],
   "source": [
    "evaluate(pass_fail_dict_ca114, normgi_ca114, diff_ca114, marks_ca114, exam_weeks_ca114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students_ca114 = pd.read_csv('../data/students-ca114-2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass - # students: 22, Age: 18.45, CAO (18): 387.50\n",
      "Fail - # students: 49, Age: 18.31, CAO (42): 388.93\n"
     ]
    }
   ],
   "source": [
    "compare_characteristics(pass_fail_dict_ca114, df_students_ca114)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course: CA278, Academic year: 2015/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "_course = 'ca278'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "_academic_year = (2015, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_ca278 = df_grades.iloc[get_grades(_course, _academic_year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grades_ca278)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The course CA278 'Programming Fundamentals III' was taught for the first time in 2016/2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
